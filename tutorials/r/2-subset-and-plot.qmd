---
title: Subset and Plot
author: Eli Holmes
---

::: {.callout-note title="Learning Objectives"}

1. How to crop a single data file
2. How to create a data cube with `terra`
3. How to crop a data cube to a box
:::

## Summary

In this example, we will utilize the `earthdatalogin` R package to retrieve, subset, and crop sea surface temperature data as a file and as a datacube from [NASA Earthdata search](https://search.earthdata.nasa.gov/search). The `earthdatalogin` R package simplifies the process of discovering and accessing NASA Earth science data.

For more on `earthdatalogin` visit the [`earthdatalogin` GitHub](https://github.com/boettiger-lab/earthdatalogin/) page and/or the [`earthdatalogin` documentation](https://boettiger-lab.github.io/earthdatalogin/) site. Be aware that `earthdatalogin` is under active development and that we are using the development version on GitHub.

## Terminology

- **`Zarr` files**: is a community project to develop specifications and software for storage of large N-dimensional typed arrays, also commonly known as tensors. A particular focus of Zarr is to provide support for storage using distributed systems like cloud object stores, and to enable efficient I/O for parallel computing applications. Learn more [here](https://zarr.dev/). 
- **Open Data Cube (ODC)**: is an Open Source Geospatial Data Management and Analysis Software project that helps you harness the power of Satellite data. At its core, the ODC is a set of Python libraries and PostgreSQL database that helps you work with geospatial raster data. The ODC seeks to increase the value and impact of global Earth observation satellite data by providing an open and freely accessible exploitation architecture. Learn more [here](https://www.opendatacube.org/). 

## Prerequisites

The tutorials today can be run with the guest Earthdata Login that is in `earthdatalogin`. 
However, if you will be using the NASA Earthdata portal more regularly, please register for an 
Earthdata Login account. Please <https://urs.earthdata.nasa.gov> to register and manage your 
Earthdata Login account. This account is free to create and only takes a moment to set up.

## Load Required Packages

We are using the JupyterHub and all necessary packages are already installed for you.

*Note: See the set-up tab (in left nav bar) for instructions on getting set up on your own computer, but
be aware that it is common to run into trouble getting GDAL set up properly to handle
netCDF files. Using a Docker image (and Python) is often less aggravating.*

```{r message=FALSE}
library(earthdatalogin)
library(lubridate)
library(terra)
```

## Get a vector of urls to our nc files

Authenticate.

```{r}
earthdatalogin::edl_netrc() 
```

Get the urls. The `results` object is a vector of urls pointing to our `netCDF` files in the cloud. Each `netCDF` file is circa 670Mb.

```{r results_MUR}
short_name <- 'MUR-JPL-L4-GLOB-v4.1'
bbox <- c(xmin=-75.5, ymin=33.5, xmax=-73.5, ymax=35.5) 
tbox <- c("2020-01-16", "2020-12-16")

results <- earthdatalogin::edl_search(
  short_name = short_name,
  version = "4.1",
  temporal = tbox, 
  bounding_box = paste(bbox,collapse=",")
)
length(results)
results[1:3]
```

## Crop and plot one netCDF file

Each MUR SST `netCDF` file is large so I do not want to download. Instead I will use `terra::rast()` to do subset the data on the server side. `vsi = TRUE` is letting function know that these are files in the cloud and to use GDAL functionality for that type of resource.

```{r get_one_MUR}
ras <- terra::rast(results[1], vsi=TRUE)
```

*Getting errors? Scroll below to the troubleshooting section.*

Crop to a very small region.

```{r crop_MUR}
# note order of terms is different than in bbox!!
e <- terra::ext(c(xmin=-75.5, xmax=-73.5,  ymin=33.5, ymax=35.5 ))
rc <- terra::crop(ras, e)
rc
```

Plot:
```{r plot_MUR}
plot(rc[[c(1, 2)]])
```


## Crop and plot multiple netCDF files

We can send multiple urls to `terra`. 

```{r get_four_MUR}
ras_all <- terra::rast(results[c(1:4)], vsi = TRUE)
ras_all
```

Crop to a small extent. Note order of terms is different than in bbox! Since we will only plot sst for this example, it is faster to first select our variable of interest.

```{r crop_four_MUR}
e <- terra::ext(c(xmin=-75.5, xmax=-73.5,  ymin=33.5, ymax=35.5 ))
ras_sst <- ras_all["analysed_sst",]
rc_sst <- terra::crop(ras_sst, e)
rc_sst
```

Convert Kelvin to Celsius.

```{r}
rc_sst <- rc_sst - 273.15
```

Now plot. We will set the range so it is the same across plots and clean up the titles to be just day without time.

```{r plot_four_MUR}
titles <- terra::time(x = rc_sst) |> lubridate::date() |> as.character()
plot(rc_sst, 
     range = c(16, 26),
     main = titles)
```

## Reading in a `Zarr` file

Reading in `Zarr` files is easy in Python with [`xarray`](https://docs.xarray.dev/en/latest/index.html) but currently this is difficult in R. See the [`gdalcubes.qmd` file](https://github.com/nmfs-opensci/EDMW-EarthData-Workshop-2024/blob/main/tutorials/r/gdalcubes.qmd) in the [`tutorials/r`](https://github.com/nmfs-opensci/EDMW-EarthData-Workshop-2024/tree/main/tutorials/r) directory of this GitHub repository. However we can open individual files from a `Zarr` file. 

Read one file.

```{r read_one_Zarr}
url <- "https://mur-sst.s3.us-west-2.amazonaws.com/zarr-v1"
prefixes <- 'ZARR:\"/vsicurl/'
slice <- '\":/analysed_sst:0"'
addr <- paste0(prefixes, url, slice)
y = terra::rast(addr)
```

Plot.

```{r}
e <- terra::ext(c(xmin=-75.5, xmax=-73.5,  ymin=33.5, ymax=35.5 ))
y |> terra::crop(e) |> terra::plot()
```

Read multiple files.

```{r}
vrt <- function(i) {
  prefix <-  'ZARR:\"/vsicurl/'
  url <- "https://mur-sst.s3.us-west-2.amazonaws.com/zarr-v1"
  slice <- paste0('\":/analysed_sst:',i,'"')
  paste0(prefix, url, slice)
}
```

```{r}
y <- terra::rast(vrt(0:3))
e <- terra::ext(c(xmin=-75.5, xmax=-73.5,  ymin=33.5, ymax=35.5 ))
y |> terra::crop(e) |> terra::plot()
```

## Conclusions

Some really cool things just happened here! You connected to multiple remote-sensing files (`netCDF`) in the cloud and worked with them without directly downloading them.

